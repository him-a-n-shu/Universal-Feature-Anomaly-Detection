{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06454c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import cv2 # Import OpenCV for contour detection\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f840ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load the Universal Feature Extractor ---\n",
    "backbone_arch = models.wide_resnet50_2(weights=None)\n",
    "feature_extractor = nn.Sequential(*list(backbone_arch.children())[:-2]).to(device)\n",
    "feature_extractor.load_state_dict(torch.load(\"universal_feature_extractor.pth\"))\n",
    "feature_extractor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812ce35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load the Product-Specific Coreset ---\n",
    "product_name = \"ENTER_PRODUCT_NAME\"\n",
    "with open(f\"/kaggle/working/{product_name}_coreset.pkl\", \"rb\") as f:\n",
    "    coreset = pickle.load(f)\n",
    "print(f\"âœ… Loaded feature extractor and '{product_name}' coreset.\")\n",
    "\n",
    "# --- Prepare for efficient nearest-neighbor search ---\n",
    "print(\"Fitting nearest-neighbor search algorithm on the coreset...\")\n",
    "nn_searcher = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(coreset)\n",
    "print(\"âœ… Search algorithm ready.\")\n",
    "\n",
    "# --- Register hooks to capture intermediate features ---\n",
    "features = {}\n",
    "def get_features_hook(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output\n",
    "    return hook\n",
    "feature_extractor[5].register_forward_hook(get_features_hook('layer2'))\n",
    "feature_extractor[6].register_forward_hook(get_features_hook('layer3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d0c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Load and Preprocess a New Test Image ---\n",
    "test_image_path = \"PATH_TO_YOUR_TEST_IMAGE.jpg\" # Replace with your test image path\n",
    "image_pil = Image.open(test_image_path).convert(\"RGB\")\n",
    "image_np_orig = np.array(image_pil)\n",
    "\n",
    "inference_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "test_tensor = inference_transform(image_pil).unsqueeze(0).to(device)\n",
    "\n",
    "print(\"\\nPerforming inference on the test image...\")\n",
    "with torch.no_grad():\n",
    "    # --- Feature Extraction ---\n",
    "    _ = feature_extractor(test_tensor)\n",
    "    layer2_features = features['layer2']\n",
    "    layer3_features = features['layer3']\n",
    "    upsampled_layer3 = torch.nn.functional.interpolate(layer3_features, size=layer2_features.shape[2:], mode='bilinear', align_corners=False)\n",
    "    combined_features = torch.cat((layer2_features, upsampled_layer3), dim=1)\n",
    "    patch_embeddings = combined_features.permute(0, 2, 3, 1).flatten(0, 2).cpu().numpy()\n",
    "\n",
    "    # --- Nearest-Neighbor Search ---\n",
    "    distances, _ = nn_searcher.kneighbors(patch_embeddings)\n",
    "    patch_scores = distances.flatten()\n",
    "\n",
    "    # --- Anomaly Map Generation ---\n",
    "    feature_map_size = combined_features.shape[2:]\n",
    "    anomaly_map_low_res = patch_scores.reshape(feature_map_size)\n",
    "    \n",
    "    # Upsample to original image size\n",
    "    anomaly_map_high_res = torch.nn.functional.interpolate(\n",
    "        torch.tensor(anomaly_map_low_res).unsqueeze(0).unsqueeze(0),\n",
    "        size=image_pil.size[::-1],\n",
    "        mode='bilinear',\n",
    "        align_corners=False\n",
    "    ).squeeze().cpu().numpy()\n",
    "    \n",
    "    # --- Image-Level Scoring and Decision ---\n",
    "    image_level_score = np.max(patch_scores)\n",
    "    \n",
    "    IMAGE_THRESHOLD = 3.5 \n",
    "    decision = \"ANOMALOUS ðŸ”´\" if image_level_score > IMAGE_THRESHOLD else \"NORMAL ðŸŸ¢\"\n",
    "    print(f\"Inference complete. Image score: {image_level_score:.4f}. Decision: {decision}\")\n",
    "\n",
    "norm_anomaly_map = (\n",
    "    255 * (anomaly_map_high_res - np.min(anomaly_map_high_res)) / \n",
    "    (np.max(anomaly_map_high_res) - np.min(anomaly_map_high_res))\n",
    ").astype(np.uint8)\n",
    "\n",
    "PIXEL_THRESHOLD = 200\n",
    "_, binary_mask = cv2.threshold(norm_anomaly_map, PIXEL_THRESHOLD, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "kernel_open = np.ones((3, 3), np.uint8)\n",
    "kernel_close = np.ones((9, 9), np.uint8)\n",
    "\n",
    "cleaned_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel_open, iterations=1)\n",
    "cleaned_mask = cv2.morphologyEx(cleaned_mask, cv2.MORPH_CLOSE, kernel_close, iterations=1)\n",
    "contours, _ = cv2.findContours(cleaned_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "image_with_contours = image_np_orig.copy()\n",
    "cv2.drawContours(image_with_contours, contours, -1, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f669ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Visualize the Results ---\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "axes[0].imshow(image_pil)\n",
    "axes[0].set_title('Original Test Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "im = axes[1].imshow(anomaly_map_high_res, cmap='jet')\n",
    "axes[1].set_title('Anomaly Heatmap')\n",
    "axes[1].axis('off')\n",
    "fig.colorbar(im, ax=axes[1], orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "axes[2].imshow(image_pil)\n",
    "axes[2].imshow(anomaly_map_high_res, cmap='jet', alpha=0.5)\n",
    "axes[2].set_title(f'Overlay Heatmap - {decision}')\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].imshow(image_with_contours)\n",
    "axes[3].set_title(f'Overlay Contours - {decision}')\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.suptitle(f'Anomaly Detection for Product: {product_name.capitalize()}', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
